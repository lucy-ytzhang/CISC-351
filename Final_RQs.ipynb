{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2sE3w3zY643F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sE3w3zY643F",
    "outputId": "9f56fe25-0bea-4e49-e916-8962fd813652"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q bertopic umap-learn hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94RobZ_1JiU_",
   "metadata": {
    "id": "94RobZ_1JiU_"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56dcc9",
   "metadata": {
    "id": "2c56dcc9"
   },
   "outputs": [],
   "source": [
    "# Unzip files\n",
    "zip_review_path = \"/content/Baby_Products.csv.zip\"\n",
    "zip_meta_path = \"/content/meta_Baby_Products.csv.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_review_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"/content/\")\n",
    "with zipfile.ZipFile(zip_meta_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"/content/\")\n",
    "\n",
    "# Read files\n",
    "reviews_csv_path = \"/content/Baby_Products.csv\"\n",
    "meta_csv_path = \"/content/meta_Baby_Products.csv\"\n",
    "\n",
    "# Read data\n",
    "reviews_df = pd.read_csv(reviews_csv_path)\n",
    "meta_df = pd.read_csv(meta_csv_path, low_memory=False)\n",
    "\n",
    "if \"reviewText\" in reviews_df.columns:\n",
    "    reviews_df.rename(columns={\"reviewText\": \"text\"}, inplace=True)\n",
    "\n",
    "# Remove empty text\n",
    "reviews_df = reviews_df.dropna(subset=[\"text\"])\n",
    "reviews_df[\"text\"] = reviews_df[\"text\"].astype(str)\n",
    "reviews_df = reviews_df[reviews_df[\"text\"].str.strip() != \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07Lc3HUWaHK7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "07Lc3HUWaHK7",
    "outputId": "50daa526-45ae-446e-e47f-7b6d26ac0fc9"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sampling（5%）\n",
    "df_sampled = reviews_df.sample(frac=0.05, random_state=42)\n",
    "print(f\"The size of the dataset after sampling: {df_sampled.shape[0]}\")\n",
    "\n",
    "# VADER Sentiment Analysis\n",
    "nltk.download(\"vader_lexicon\")\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    score = sia.polarity_scores(str(text))[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df_sampled[\"label\"] = df_sampled[\"text\"].apply(get_vader_sentiment)\n",
    "\n",
    "df_sampled = df_sampled.sample(n=3000, random_state=42)\n",
    "\n",
    "print(\"\\nThe number of each sentiment category：\")\n",
    "print(df_sampled[\"label\"].value_counts())\n",
    "\n",
    "# Save data\n",
    "df_sampled.to_csv(\"/content/df_sampled_with_labels.csv\", index=False)\n",
    "print(\"Saved df_sampled_with_labels.csv\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"label\", data=df_sampled, order=[\"Positive\", \"Neutral\", \"Negative\"])\n",
    "plt.title(\"Sentiment Distribution (VADER, Sampled 3000)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sNqZERlLP80T",
   "metadata": {
    "id": "sNqZERlLP80T"
   },
   "source": [
    "# RQ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AY6YpcthlSgw",
   "metadata": {
    "id": "AY6YpcthlSgw"
   },
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pVv3daR-lQm4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVv3daR-lQm4",
    "outputId": "96e903ac-f0c0-49b5-a255-5d22c8a3bb11"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/content/df_sampled_with_labels.csv\")\n",
    "label_map = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "df[\"label_num\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "# TextBlob\n",
    "def textblob_sentiment(text):\n",
    "    polarity = TextBlob(str(text)).sentiment.polarity\n",
    "    if polarity >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif polarity <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df[\"tb_label\"] = df[\"text\"].apply(textblob_sentiment)\n",
    "tb_y_true = df[\"label_num\"]\n",
    "tb_y_pred = df[\"tb_label\"].map(label_map)\n",
    "\n",
    "tb_acc = accuracy_score(tb_y_true, tb_y_pred)\n",
    "tb_prec = precision_score(tb_y_true, tb_y_pred, average=\"weighted\")\n",
    "tb_rec = recall_score(tb_y_true, tb_y_pred, average=\"weighted\")\n",
    "tb_f1 = f1_score(tb_y_true, tb_y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n TextBlob Performance:\")\n",
    "print(f\"Accuracy   : {tb_acc:.4f}\")\n",
    "print(f\"Precision  : {tb_prec:.4f}\")\n",
    "print(f\"Recall     : {tb_rec:.4f}\")\n",
    "print(f\"F1 Score   : {tb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gAlMSD7mlV96",
   "metadata": {
    "id": "gAlMSD7mlV96"
   },
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YdRWwXPFlQf-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdRWwXPFlQf-",
    "outputId": "d18b609e-e1ac-4514-f25c-d0d38bda8614"
   },
   "outputs": [],
   "source": [
    "!wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip -d glove.6B\n",
    "\n",
    "import numpy as np\n",
    "import re, string\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/content/df_sampled_with_labels.csv\")\n",
    "label_map = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "df[\"label_num\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "# Glove\n",
    "glove_path = \"glove.6B/glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_path, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = vector\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\@w+|\\#\", \"\", text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    return text.split()\n",
    "\n",
    "def get_average_vector(tokens):\n",
    "    vectors = [embeddings_index[w] for w in tokens if w in embeddings_index]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "tqdm.pandas()\n",
    "X_vectors = df[\"text\"].progress_apply(lambda x: get_average_vector(preprocess(x)))\n",
    "X = np.vstack(X_vectors.values)\n",
    "y = df[\"label_num\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "glove_y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "glove_acc = accuracy_score(y_test, glove_y_pred)\n",
    "glove_prec = precision_score(y_test, glove_y_pred, average=\"weighted\")\n",
    "glove_rec = recall_score(y_test, glove_y_pred, average=\"weighted\")\n",
    "glove_f1 = f1_score(y_test, glove_y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n GloVe + LogisticRegression Performance:\")\n",
    "print(f\"Accuracy   : {glove_acc:.4f}\")\n",
    "print(f\"Precision  : {glove_prec:.4f}\")\n",
    "print(f\"Recall     : {glove_rec:.4f}\")\n",
    "print(f\"F1 Score   : {glove_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GD1TKGLjlXIh",
   "metadata": {
    "id": "GD1TKGLjlXIh"
   },
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8DVVbH_7lQUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "8DVVbH_7lQUF",
    "outputId": "120915ec-5f25-438d-8a39-8d6c8f87168a"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/content/df_sampled_with_labels.csv\")\n",
    "df[\"label_num\"] = df[\"label\"].map({\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2})\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df[\"label_num\"].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "test_encodings = tokenize(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"labels\": train_labels\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"labels\": test_labels\n",
    "})\n",
    "\n",
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    fp16=False\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")\n",
    "    rec = recall_score(labels, preds, average=\"weighted\")\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "bert_acc = eval_results[\"eval_accuracy\"]\n",
    "bert_prec = eval_results[\"eval_precision\"]\n",
    "bert_rec = eval_results[\"eval_recall\"]\n",
    "bert_f1 = eval_results[\"eval_f1\"]\n",
    "\n",
    "print(\"\\n DistilBERT Performance:\")\n",
    "print(f\"Accuracy   : {bert_acc:.4f}\")\n",
    "print(f\"Precision  : {bert_prec:.4f}\")\n",
    "print(f\"Recall     : {bert_rec:.4f}\")\n",
    "print(f\"F1 Score   : {bert_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6xKO7JisuTq3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "6xKO7JisuTq3",
    "outputId": "2ab6e67e-1d0f-4951-82a8-d40b7f5ecf09"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"TextBlob\", \"GloVe + LR\", \"DistilBERT\"],\n",
    "    \"Accuracy\": [tb_acc, glove_acc, bert_acc],\n",
    "    \"Precision\": [tb_prec, glove_prec, bert_prec],\n",
    "    \"Recall\": [tb_rec, glove_rec, bert_rec],\n",
    "    \"F1 Score\": [tb_f1, glove_f1, bert_f1]\n",
    "})\n",
    "\n",
    "# Print result\n",
    "print(\"\\n Model Performance Comparison Table:\")\n",
    "display(results.round(4))\n",
    "\n",
    "# Graph\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "x = np.arange(len(metrics))  # [0, 1, 2, 3]\n",
    "bar_width = 0.25\n",
    "\n",
    "scores = results.iloc[:, 1:].values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    plt.bar(x + i * bar_width, scores[i], width=bar_width, label=results[\"Model\"][i])\n",
    "\n",
    "plt.xticks(x + bar_width, metrics)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Comparison Across Evaluation Metrics\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jK3cCXbIPwpK",
   "metadata": {
    "id": "jK3cCXbIPwpK"
   },
   "source": [
    "# RQ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p-m1lEGWTSZW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-m1lEGWTSZW",
    "outputId": "32106d95-0c69-4280-c561-5819e8f52ed7"
   },
   "outputs": [],
   "source": [
    "# Sampling\n",
    "df_sampled = reviews_df.sample(n=8000, random_state=42)\n",
    "\n",
    "# VADER\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    score = sia.polarity_scores(str(text))[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df_sampled[\"label\"] = df_sampled[\"text\"].apply(get_vader_sentiment)\n",
    "\n",
    "# Save file\n",
    "df_sampled.to_csv(\"/content/df_sampled_with_labels_for_RQ2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R6gLJ8Y5PwWc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d1ccda0ef73541a7a7187601192e581e",
      "ad6f51ed636c4f3ab94ea64d819cea84",
      "9dea5ba349ba4082b404e347aa00c0f3",
      "85d67aeeb3a345138234a6503aebde47",
      "4a38fc43f63747859c49664daff66d1e",
      "1bcd34e3d2864dfeaf478f90f627fdbf",
      "da2b4cc53f494b4f9d13c3262bfae46d",
      "26a15538bfe748d5b5ce061f10bad8a9",
      "85a483fea51f42bfab436d296f6724d3",
      "9db64f1922864a83b0e8a02e8d339eb9",
      "4b7ed7e4ffd34621b8923b54ef43b975",
      "df64c044d1c04a18882ae65c4cbd568e",
      "ddad1b3a8e814915988e7924964e091f",
      "0555df73c94f41dd896190848965a806",
      "1e7a943ad6ca4219ad93b320901b2c2e",
      "758a354ad62c431d8ef81827b5c5a2ec",
      "330388da87f84a7b8877fcfe797548fe",
      "c68bddfd28324d01bf6e2cc9d8910c8f",
      "dbb433f2512243edbea4d4502d6cd8d5",
      "ef7adc5aa8ec4be8a2cd5a26f7163d88",
      "e0845a035c30412aa14006343519417a",
      "b953b076117d400b8be7ac6755eec20e",
      "cb9c9e74ae864e1594a64af51a6d5dd2",
      "52d6426829464254b07a63d7d91854e5",
      "6771a7c85b5142248034d2c580f07ed3",
      "037e82c2bde0400885cddba7e9d8b075",
      "f0a49f9258244ba3b1df43507b50edab",
      "1a180250dc954a188f3e61582cbd8688",
      "3157f6c4364d47218b5115aaf50fcbca",
      "b387ff2fef694c789975637b1e263c70",
      "b817eec3731a4d2986fd364ba072fdb7",
      "a1c4e6fdf9e24f0a848e5abb68682690",
      "258a5b2052444ac08d984b6fd5525adb",
      "4f4be62d679b43319fdcdaadd7390472",
      "46424fa611a84d18b7ea43625d0107b0",
      "017ee74e83154c44984c9b8a782aa73d",
      "f31272c254194e1ab50ba0f752147d77",
      "53c5ff0312064a479c38e935270b57cc",
      "d4514e30f72a4296b5d792c3e938d873",
      "794d877821164656b6a0588130a73b8d",
      "42da594286d344818c475cff48aa2f35",
      "583464ebe5ad483b830c45e0cf15bcc1",
      "23ea74e385f743e8ae75132c6ea7133f",
      "1403eb1be1e248189de1a4ad43c94c1b",
      "de6d79f6bff0493a9ecad31e35b6b7ac",
      "37fa522d90774ccbbb155abe9b8314c9",
      "775991e1ae944388ae93e447a137e89e",
      "82912ef5e28248b1a68b969820f6d1b4",
      "edaa8be0a7ed4ff08d5d6e9b33b49f96",
      "338c998447c74bd8bc787d82386da133",
      "24ce6e7b06e64aec8a74552393cc0426",
      "ad9f8d2b02254f55a819e2a21a294561",
      "55e2afd01e4447f58d31e719fe8a32a0",
      "2474c482682c432cb8e15d17e49eb305",
      "6a9597b4891e46e6bef6252c07ce0fc9",
      "30d2f472292e472ebb89c8d6c44598f8",
      "9a378b4b5c164bab9c937d906b262c71",
      "126fd3445c8d4b9f9f11e45e5494d6df",
      "125e298b0c274e329bb26b4e0a0498db",
      "fb621e7aec364ad28e64c55e4c295367",
      "7851b8b5615c4bfba08ba87c08832206",
      "f79421fa62734d6f8211288361cccbe1",
      "c5dc50b4e745400787ea88e040a6ced9",
      "cec346d6b47b4373972f6c0f1a71ca13",
      "c80b4360ca194bd6b2fdb002bf8571f8",
      "f97bdfe826f449b5aa59aa49aeb692bb",
      "1a97e233af82480a9e94b36265af1a45",
      "79a234847cf14f8b98eac68359336b4c",
      "2c86c1c2a326473a931aa627ec5fcf3b",
      "8aab976197814778a438128901cb2669",
      "2b896f0040f346b398c44aed6a0763bb",
      "983e091329f045eaa3e442cf0db0f209",
      "bd5f249d65ff477e89d14f0bc8c8bab5",
      "02447e06ae814acd9ffc27bdd7f3de65",
      "5c8ffc91f06e47f490f1bd5bd1e59526",
      "6fd16e8df7ce4ca9a41cf6790f93c593",
      "6963f1fba57d4a1cad432f489fd55789",
      "940d19a2b3314443af392d6190ab01bb",
      "7b2e2bdc94e9430aa8049fb9f728b9b9",
      "7a5f700c0de04a4a8a715d63ffd39cfc",
      "484d116341554d2a8ecb7f7fca0db460",
      "209c9cdd07944315a0d3cb692870546c",
      "d3d0599ea62a4812b7aaef2c055c296f",
      "4bd1df73181f4c8b9b5ab2846f278670",
      "366e0632d5dd4038a4e470cb9e14f418",
      "3cda3c8996ac4980ac01a3ef822645c8",
      "bbbd8083b7d34d1f8d3087ecbf26d921",
      "fbe305201ae74e9aacac51706fe8d067",
      "d37b143568794251a3c21a58766f6b43",
      "fa80e4833bb34905ac73e9b5c4768eeb",
      "ce3d8c2bdb954ba295e0e9b09504b513",
      "6cb596f7d7d14c9cac89233c8200bc69",
      "08aaf35b8bb443ed921ce62561277743",
      "3ac8756309ca4492a8a093be2df63e2f",
      "0b75791b83b346c6ad949c59f25f4741",
      "94ed1fa24e97499cb8745dcaa6ae5e89",
      "4dddcb3aa04c4418959248b3e2757a42",
      "3d6f33d8324246dcbd4e018447542113",
      "ac01f5edf6f243bb8204c529e52ccdf1",
      "a347d847934141ad9cf302d4b5439a7f",
      "bf9c0cfd0447431589e39d4b52b5af1c",
      "fa5d34c8e88b47c48b42797fb57c02c5",
      "e424fd1fc87243ed87a2da5489ea147c",
      "c55fd727028c46e0a3f9dbc05c87fef5",
      "b3c809375d4847c6878e619c92336a4a",
      "7f3143e898ec4ec3a34b5111fe8d7df7",
      "c652d147fb124c5fa95002391ed51d85",
      "352aec6c6a5b4934881ac28a5bf58b46",
      "a89bb4db62024a05b8b1228f122ac195",
      "c05831e17f94463cb345d8d9fca9944c",
      "25a87f317a7a44668b648aac916f3d59",
      "957dc4a936f4491d9cb0ae285fda48f7",
      "b4df1cb35f0b458487ff979d72bb94ce",
      "aaf3a3e2101b4387bebded8d2d4ec528",
      "38e647a70a844e29a3ce801af0edecbf",
      "0ef4cd6d8bed4e44be2895de632934ce",
      "3a813ccaf59a46a9a856550e99b87aec",
      "abefdcf1e51242c5a7a9d569969c4a41",
      "ab59ab85a5604a6fb0b5674b9aa18ee9",
      "97fbcea7059548b0b316c379d392385a",
      "fbff9692fe80458187e192845af7084b",
      "b56c03e81a614cf8bdf4b9646da43cda",
      "8b1728af3d8d47bdbd3470a62ab03a40",
      "38647599908a46109da08ba909c5940d",
      "3bc122c679134b79b61042726cbf4306",
      "9de00444302e424cae01f764cbb9dff6",
      "b4809966352f4154904392d7ba5f1936",
      "88b92bb738644b1b81438091fd1836d5",
      "aecaed891f044370b7430d4d77566c19",
      "20294095121d437ca06fd68f2dca97cf",
      "8f7643e3ef6d452983d5cfe39892df77",
      "69a132fd79454798a8c5977a8853d38d"
     ]
    },
    "id": "R6gLJ8Y5PwWc",
    "outputId": "c5881ed2-2116-4f04-f6e5-b5f472499557"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bertopic import BERTopic\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Load file\n",
    "df = pd.read_csv(\"/content/df_sampled_with_labels_for_RQ2.csv\")\n",
    "\n",
    "# Text clearning\n",
    "custom_stopwords = ENGLISH_STOP_WORDS.union({\n",
    "    \"de\", \"el\", \"la\", \"los\", \"las\", \"es\", \"una\", \"un\", \"por\", \"para\",\n",
    "    \"muy\", \"con\", \"en\", \"al\", \"lo\", \"que\", \"se\", \"y\", \"a\", \"su\", \"del\", \"no\", \"me\",\n",
    "    \"mi\", \"producto\", \"como\", \"más\", \"pero\"\n",
    "})\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = str(text).lower().split()\n",
    "    tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "texts = df[\"clean_text\"].astype(str).tolist()\n",
    "\n",
    "# BERTopic\n",
    "topic_model = BERTopic(language=\"english\", verbose=True, min_topic_size=10)\n",
    "topics, _ = topic_model.fit_transform(texts)\n",
    "df[\"topic\"] = topics\n",
    "\n",
    "# Remove outlier\n",
    "df_clean = df[df[\"topic\"] != -1]\n",
    "\n",
    "# Analyze sentiment\n",
    "sentiment_dist = df_clean.groupby([\"topic\", \"label\"]).size().unstack().fillna(0)\n",
    "\n",
    "def get_topic_name(topic_id):\n",
    "    words = topic_model.get_topic(topic_id)\n",
    "    return \" / \".join([w[0] for w in words[:2]])\n",
    "\n",
    "sentiment_dist.index = [get_topic_name(i) for i in sentiment_dist.index]\n",
    "\n",
    "# Graph\n",
    "top_n = 10\n",
    "top_topics = sentiment_dist.sum(axis=1).sort_values(ascending=False).head(top_n).index\n",
    "\n",
    "ax = sentiment_dist.loc[top_topics].plot(\n",
    "    kind=\"barh\",\n",
    "    stacked=True,\n",
    "    figsize=(10, 6),\n",
    "    title=\"Sentiment Distribution by Topic (Cleaned, No Outlier)\"\n",
    ")\n",
    "plt.xlabel(\"Review Count\")\n",
    "plt.ylabel(\"Topic (Top Words)\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "for i, topic in enumerate(top_topics):\n",
    "    total = sentiment_dist.loc[topic].sum()\n",
    "    ax.text(total + 5, i, f\"{int(total)}\", va='center', fontsize=9, color=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_clean.to_csv(\"/content/df_sampled_with_labels_and_topics_cleaned.csv\", index=False)\n",
    "print(\" Saved df_sampled_with_labels_and_topics_cleaned.csv\")\n",
    "\n",
    "# Save file\n",
    "topic_model.save(\"/content/final_model\")\n",
    "print(\" Saved BERTopic model to /content/final_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-svkL_dk60w8",
   "metadata": {
    "id": "-svkL_dk60w8"
   },
   "source": [
    "# RQ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WmI92po_62Y0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WmI92po_62Y0",
    "outputId": "8f531f63-ed38-4984-cee2-17c852d0cb8e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load file\n",
    "rq2_path = \"/content/df_sampled_with_labels_and_topics_cleaned.csv\"\n",
    "\n",
    "df_topics = pd.read_csv(rq2_path)\n",
    "df_topics = df_topics.sample(n=3000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Clean data\n",
    "df_reviews = pd.read_csv(\"/content/Baby_Products.csv\")\n",
    "df_reviews.columns = df_reviews.columns.str.strip().str.lower()\n",
    "\n",
    "if \"asin\" not in df_reviews.columns and \"parent_asin\" in df_reviews.columns:\n",
    "    df_reviews.rename(columns={\"parent_asin\": \"asin\"}, inplace=True)\n",
    "\n",
    "for col in [\"text\", \"rating\", \"asin\"]:\n",
    "    if col not in df_reviews.columns:\n",
    "        raise ValueError(f\" df_reviews 缺失字段：{col}\")\n",
    "\n",
    "df_reviews = df_reviews[[\"text\", \"rating\", \"asin\"]].dropna()\n",
    "df_reviews[\"rating\"] = df_reviews[\"rating\"].astype(float).astype(int)\n",
    "\n",
    "# Merge data\n",
    "df = df_topics.merge(df_reviews, on=\"text\", how=\"left\", suffixes=('_topics', '_reviews'))\n",
    "\n",
    "if \"rating_reviews\" in df.columns and \"asin_reviews\" in df.columns:\n",
    "    df.rename(columns={\"rating_reviews\": \"rating\", \"asin_reviews\": \"asin\"}, inplace=True)\n",
    "\n",
    "if \"asin\" not in df.columns:\n",
    "    raise ValueError(\" still missing\")\n",
    "\n",
    "df = df.dropna(subset=[\"asin\"])\n",
    "\n",
    "# Load file\n",
    "df_meta = pd.read_csv(\"/content/meta_Baby_Products.csv\")\n",
    "df_meta.columns = df_meta.columns.str.strip().str.lower()\n",
    "\n",
    "asin_col = \"asin\" if \"asin\" in df_meta.columns else \"parent_asin\"\n",
    "if \"main_category\" not in df_meta.columns:\n",
    "    raise ValueError(\" meta_Baby_Products.csv 缺少 main_category 字段\")\n",
    "\n",
    "df_meta = df_meta[[asin_col, \"main_category\"]].rename(columns={asin_col: \"asin\"})\n",
    "df = df.merge(df_meta, on=\"asin\", how=\"left\")\n",
    "\n",
    "# Rating-label mismatch\n",
    "def check_mismatch(row):\n",
    "    if row[\"label\"] == \"Positive\" and row[\"rating\"] <= 3:\n",
    "        return \"Mismatch\"\n",
    "    elif row[\"label\"] == \"Negative\" and row[\"rating\"] >= 4:\n",
    "        return \"Mismatch\"\n",
    "    elif row[\"label\"] == \"Neutral\" and (row[\"rating\"] <= 2 or row[\"rating\"] >= 4):\n",
    "        return \"Mismatch\"\n",
    "    else:\n",
    "        return \"Match\"\n",
    "\n",
    "df[\"match_status\"] = df.apply(check_mismatch, axis=1)\n",
    "\n",
    "# Ratio of mismatch\n",
    "category_summary = df.groupby([\"main_category\", \"match_status\"]).size().unstack(fill_value=0)\n",
    "category_summary[\"Total\"] = category_summary.sum(axis=1)\n",
    "category_summary[\"Mismatch Ratio\"] = category_summary[\"Mismatch\"] / category_summary[\"Total\"]\n",
    "category_summary = category_summary.sort_values(\"Mismatch Ratio\", ascending=False).reset_index()\n",
    "\n",
    "# Graph\n",
    "def get_mismatch_type(row):\n",
    "    if row[\"label\"] == \"Positive\" and row[\"rating\"] <= 3:\n",
    "        return \"Positive Text + Low Rating\"\n",
    "    elif row[\"label\"] == \"Negative\" and row[\"rating\"] >= 4:\n",
    "        return \"Negative Text + High Rating\"\n",
    "    elif row[\"label\"] == \"Neutral\" and row[\"rating\"] != 3:\n",
    "        return \"Neutral Text + Extreme Rating\"\n",
    "    else:\n",
    "        return \"Match\"\n",
    "\n",
    "df[\"mismatch_type\"] = df.apply(get_mismatch_type, axis=1)\n",
    "\n",
    "\n",
    "# Pie chart\n",
    "type_counts = df[\"mismatch_type\"].value_counts()\n",
    "labels = type_counts.index.tolist()\n",
    "sizes = type_counts.values\n",
    "colors = sns.color_palette(\"pastel\", len(labels))\n",
    "# Negative text + High Rating is 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "wedges, _ = ax.pie(sizes, startangle=140, colors=colors, wedgeprops=dict(edgecolor='white'))\n",
    "\n",
    "total = sum(sizes)\n",
    "for i, (w, label) in enumerate(zip(wedges, labels)):\n",
    "    percent = sizes[i] / total\n",
    "    if percent > 0.005:\n",
    "        angle = (w.theta2 + w.theta1) / 2\n",
    "        x = np.cos(np.deg2rad(angle))\n",
    "        y = np.sin(np.deg2rad(angle))\n",
    "        ha = \"left\" if x > 0 else \"right\"\n",
    "        ax.annotate(f\"{label}: {percent:.1%}\",\n",
    "                    xy=(x, y),\n",
    "                    xytext=(1.3 * x, 1.3 * y),\n",
    "                    ha=ha, va=\"center\",\n",
    "                    arrowprops=dict(arrowstyle=\"-\", lw=1),\n",
    "                    fontsize=10)\n",
    "\n",
    "ax.set_title(\"Distribution of Mismatch Types\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=category_summary.head(15), x=\"Mismatch Ratio\", y=\"main_category\", color=\"salmon\")\n",
    "plt.title(\"Top 15 Product Categories by Rating-Sentiment Mismatch\", fontsize=14)\n",
    "plt.xlabel(\"Mismatch Ratio\")\n",
    "plt.ylabel(\"Product Category\")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mismatch example\n",
    "sample_mismatches = df[df[\"match_status\"] == \"Mismatch\"][[\"text\", \"label\", \"rating\", \"main_category\", \"mismatch_type\"]].sample(5, random_state=42)\n",
    "print(\"🔍 示例 Mismatch Review:\")\n",
    "display(sample_mismatches)\n",
    "\n",
    "# Save file\n",
    "df.to_csv(\"/content/df_RQ3_combined.csv\", index=False)\n",
    "category_summary.to_csv(\"/content/category_mismatch_summary.csv\", index=False)\n",
    "print(\" Saved: df_RQ3_combined.csv & category_mismatch_summary.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
